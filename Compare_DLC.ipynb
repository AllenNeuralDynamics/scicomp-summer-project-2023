{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0691231",
   "metadata": {},
   "source": [
    "## DLC\n",
    "\n",
    "In `config.yaml` specify the body parts and the training fraction `0.8`. Label frames and saving will create a `.csv` file in the `labeled-data` folder containing the label coordinates. After labeling the extracted frames, `create training dataset` will combine the labeled datasets from all the videos and split them to create train and test datasets. The training data will be used to train the network, while the test data set will be used for evaluating the network. Notice that you may create multiple separate training datasets by changing the shuffle number. \n",
    "\n",
    "- Modify the training network to only do 20 iterations. You can modify the training parameters in the GUI directory or in the `dlc-models\\iteration0\\train\\pose_cfg.yaml` before training the network. \n",
    "\n",
    "Evaluate trained network will compute performance metrics such as train and test errors (**evaluation metric 1**, in `CombinedEvaluationResults` file) by comparing manual labels and predicted labels. They will be saved in the `evaluation-results` folder. \n",
    "\n",
    "Finally, you can use the network to analyze new videos (or the same video in this case). The prediction coordinates and likelihoods will be saved as an `.csv` file under the same directory as the video file. If you select the `plot trajectories` option in the GUI, it will create a `plot-poses` folder in the directory of the video, and it will contain some trajectory plots such as coordinates of body parts vs. time, likelihoods vs time.\n",
    "\n",
    "You can also create labeled videos (**evaluation metric 2**, under `videos\\mouse-top-viewDLC_resnet50_dlc-mouse-topviewJul24shuffle1_20_labeled.mp4`), modify the skeleton configurations in the `config.yaml` file to control what the skeleton should look like. \n",
    "\n",
    "- The `pcutoff` attribute in config.yaml controls the confidence / likelihood cutoff level that DLC uses to filter out predictions before creating the video. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d1b77df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 2.3.5...\n"
     ]
    }
   ],
   "source": [
    "import deeplabcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba97d986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function create_labeled_video in module deeplabcut.utils.make_labeled_video:\n",
      "\n",
      "create_labeled_video(config, videos, videotype='', shuffle=1, trainingsetindex=0, filtered=False, fastmode=True, save_frames=False, keypoints_only=False, Frames2plot=None, displayedbodyparts='all', displayedindividuals='all', codec='mp4v', outputframerate=None, destfolder=None, draw_skeleton=False, trailpoints=0, displaycropped=False, color_by='bodypart', modelprefix='', init_weights='', track_method='', superanimal_name='', pcutoff=0.6, skeleton=[], skeleton_color='white', dotsize=8, colormap='rainbow', alphavalue=0.5, overwrite=False)\n",
      "    Labels the bodyparts in a video.\n",
      "    \n",
      "    Make sure the video is already analyzed by the function\n",
      "    ``deeplabcut.analyze_videos``.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    config : string\n",
      "        Full path of the config.yaml file.\n",
      "    \n",
      "    videos : list[str]\n",
      "        A list of strings containing the full paths to videos for analysis or a path\n",
      "        to the directory, where all the videos with same extension are stored.\n",
      "    \n",
      "    videotype: str, optional, default=\"\"\n",
      "        Checks for the extension of the video in case the input to the video is a\n",
      "        directory. Only videos with this extension are analyzed.\n",
      "        If left unspecified, videos with common extensions\n",
      "        ('avi', 'mp4', 'mov', 'mpeg', 'mkv') are kept.\n",
      "    \n",
      "    shuffle : int, optional, default=1\n",
      "        Number of shuffles of training dataset.\n",
      "    \n",
      "    trainingsetindex: int, optional, default=0\n",
      "        Integer specifying which TrainingsetFraction to use.\n",
      "        Note that TrainingFraction is a list in config.yaml.\n",
      "    \n",
      "    filtered: bool, optional, default=False\n",
      "        Boolean variable indicating if filtered output should be plotted rather than\n",
      "        frame-by-frame predictions. Filtered version can be calculated with\n",
      "        ``deeplabcut.filterpredictions``.\n",
      "    \n",
      "    fastmode: bool, optional, default=True\n",
      "        If ``True``, uses openCV (much faster but less customization of video) instead\n",
      "        of matplotlib if ``False``. You can also \"save_frames\" individually or not in\n",
      "        the matplotlib mode (if you set the \"save_frames\" variable accordingly).\n",
      "        However, using matplotlib to create the frames it therefore allows much more\n",
      "        flexible (one can set transparency of markers, crop, and easily customize).\n",
      "    \n",
      "    save_frames: bool, optional, default=False\n",
      "        If ``True``, creates each frame individual and then combines into a video.\n",
      "        Setting this to ``True`` is relatively slow as it stores all individual frames.\n",
      "    \n",
      "    keypoints_only: bool, optional, default=False\n",
      "        By default, both video frames and keypoints are visible. If ``True``, only the\n",
      "        keypoints are shown. These clips are an hommage to Johansson movies,\n",
      "        see https://www.youtube.com/watch?v=1F5ICP9SYLU and of course his seminal\n",
      "        paper: \"Visual perception of biological motion and a model for its analysis\"\n",
      "        by Gunnar Johansson in Perception & Psychophysics 1973.\n",
      "    \n",
      "    Frames2plot: List[int] or None, optional, default=None\n",
      "        If not ``None`` and ``save_frames=True`` then the frames corresponding to the\n",
      "        index will be plotted. For example, ``Frames2plot=[0,11]`` will plot the first\n",
      "        and the 12th frame.\n",
      "    \n",
      "    displayedbodyparts: list[str] or str, optional, default=\"all\"\n",
      "        This selects the body parts that are plotted in the video. If ``all``, then all\n",
      "        body parts from config.yaml are used. If a list of strings that are a subset of\n",
      "        the full list. E.g. ['hand','Joystick'] for the demo\n",
      "        Reaching-Mackenzie-2018-08-30/config.yaml to select only these body parts.\n",
      "    \n",
      "    displayedindividuals: list[str] or str, optional, default=\"all\"\n",
      "        Individuals plotted in the video.\n",
      "        By default, all individuals present in the config will be showed.\n",
      "    \n",
      "    codec: str, optional, default=\"mp4v\"\n",
      "        Codec for labeled video. For available options, see\n",
      "        http://www.fourcc.org/codecs.php. Note that this depends on your ffmpeg\n",
      "        installation.\n",
      "    \n",
      "    outputframerate: int or None, optional, default=None\n",
      "        Positive number, output frame rate for labeled video (only available for the\n",
      "        mode with saving frames.) If ``None``, which results in the original video\n",
      "        rate.\n",
      "    \n",
      "    destfolder: string or None, optional, default=None\n",
      "        Specifies the destination folder that was used for storing analysis data. If\n",
      "        ``None``, the path of the video file is used.\n",
      "    \n",
      "    draw_skeleton: bool, optional, default=False\n",
      "        If ``True`` adds a line connecting the body parts making a skeleton on each\n",
      "        frame. The body parts to be connected and the color of these connecting lines\n",
      "        are specified in the config file.\n",
      "    \n",
      "    trailpoints: int, optional, default=0\n",
      "        Number of previous frames whose body parts are plotted in a frame\n",
      "        (for displaying history).\n",
      "    \n",
      "    displaycropped: bool, optional, default=False\n",
      "        Specifies whether only cropped frame is displayed (with labels analyzed\n",
      "        therein), or the original frame with the labels analyzed in the cropped subset.\n",
      "    \n",
      "    color_by : string, optional, default='bodypart'\n",
      "        Coloring rule. By default, each bodypart is colored differently.\n",
      "        If set to 'individual', points belonging to a single individual are colored the\n",
      "        same.\n",
      "    \n",
      "    modelprefix: str, optional, default=\"\"\n",
      "        Directory containing the deeplabcut models to use when evaluating the network.\n",
      "        By default, the models are assumed to exist in the project folder.\n",
      "    \n",
      "    init_weights: str,\n",
      "        Checkpoint path to the super model\n",
      "    track_method: string, optional, default=\"\"\n",
      "        Specifies the tracker used to generate the data.\n",
      "        Empty by default (corresponding to a single animal project).\n",
      "        For multiple animals, must be either 'box', 'skeleton', or 'ellipse' and will\n",
      "        be taken from the config.yaml file if none is given.\n",
      "    \n",
      "    overwrite: bool, optional, default=False\n",
      "        If ``True`` overwrites existing labeled videos.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "        results : list[bool]\n",
      "        ``True`` if the video is successfully created for each item in ``videos``.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    \n",
      "    Create the labeled video for a single video\n",
      "    \n",
      "    >>> deeplabcut.create_labeled_video(\n",
      "            '/analysis/project/reaching-task/config.yaml',\n",
      "            ['/analysis/project/videos/reachingvideo1.avi'],\n",
      "        )\n",
      "    \n",
      "    Create the labeled video for a single video and store the individual frames\n",
      "    \n",
      "    >>> deeplabcut.create_labeled_video(\n",
      "            '/analysis/project/reaching-task/config.yaml',\n",
      "            ['/analysis/project/videos/reachingvideo1.avi'],\n",
      "            fastmode=True,\n",
      "            save_frames=True,\n",
      "        )\n",
      "    \n",
      "    Create the labeled video for multiple videos\n",
      "    \n",
      "    >>> deeplabcut.create_labeled_video(\n",
      "            '/analysis/project/reaching-task/config.yaml',\n",
      "            [\n",
      "                '/analysis/project/videos/reachingvideo1.avi',\n",
      "                '/analysis/project/videos/reachingvideo2.avi',\n",
      "            ],\n",
      "        )\n",
      "    \n",
      "    Create the labeled video for all the videos with an .avi extension in a directory.\n",
      "    \n",
      "    >>> deeplabcut.create_labeled_video(\n",
      "            '/analysis/project/reaching-task/config.yaml',\n",
      "            ['/analysis/project/videos/'],\n",
      "        )\n",
      "    \n",
      "    Create the labeled video for all the videos with an .mp4 extension in a directory.\n",
      "    \n",
      "    >>> deeplabcut.create_labeled_video(\n",
      "            '/analysis/project/reaching-task/config.yaml',\n",
      "            ['/analysis/project/videos/'],\n",
      "            videotype='mp4',\n",
      "        )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(deeplabcut.create_labeled_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6832cb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\louise.xu\\projects\\Deeplabcut\\examples\\openfield-Pranav-2018-10-30\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'dlc-models\\\\iteration-0\\\\openfieldOct30-trainset95shuffle1\\\\train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mlouise.xu\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mprojects\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDeeplabcut\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mexamples\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mopenfield-Pranav-2018-10-30\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mdeeplabcut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_labeled_video\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconfig.yaml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./videos/m3v1mp4.mp4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\utils\\make_labeled_video.py:560\u001b[0m, in \u001b[0;36mcreate_labeled_video\u001b[1;34m(config, videos, videotype, shuffle, trainingsetindex, filtered, fastmode, save_frames, keypoints_only, Frames2plot, displayedbodyparts, displayedindividuals, codec, outputframerate, destfolder, draw_skeleton, trailpoints, displaycropped, color_by, modelprefix, init_weights, track_method, superanimal_name, pcutoff, skeleton, skeleton_color, dotsize, colormap, alphavalue, overwrite)\u001b[0m\n\u001b[0;32m    555\u001b[0m     track_method \u001b[38;5;241m=\u001b[39m auxfun_multianimal\u001b[38;5;241m.\u001b[39mget_track_method(\n\u001b[0;32m    556\u001b[0m         cfg, track_method\u001b[38;5;241m=\u001b[39mtrack_method\n\u001b[0;32m    557\u001b[0m     )\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m init_weights \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 560\u001b[0m     DLCscorer, DLCscorerlegacy \u001b[38;5;241m=\u001b[39m \u001b[43mauxiliaryfunctions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGetScorerName\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    561\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainFraction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodelprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodelprefix\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# automatically loads corresponding model (even training iteration based on snapshot index)\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    564\u001b[0m     DLCscorer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDLC_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m Path(init_weights)\u001b[38;5;241m.\u001b[39mstem\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\utils\\auxiliaryfunctions.py:592\u001b[0m, in \u001b[0;36mget_scorer_name\u001b[1;34m(cfg, shuffle, trainFraction, trainingsiterations, modelprefix)\u001b[0m\n\u001b[0;32m    584\u001b[0m     snapshotindex \u001b[38;5;241m=\u001b[39m cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msnapshotindex\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    586\u001b[0m modelfolder \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m    587\u001b[0m     cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject_path\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    588\u001b[0m     \u001b[38;5;28mstr\u001b[39m(get_model_folder(trainFraction, shuffle, cfg, modelprefix\u001b[38;5;241m=\u001b[39mmodelprefix)),\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    590\u001b[0m )\n\u001b[0;32m    591\u001b[0m Snapshots \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[1;32m--> 592\u001b[0m     [fn\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m fn \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelfolder\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m fn]\n\u001b[0;32m    593\u001b[0m )\n\u001b[0;32m    594\u001b[0m increasing_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort([\u001b[38;5;28mint\u001b[39m(m\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m Snapshots])\n\u001b[0;32m    595\u001b[0m Snapshots \u001b[38;5;241m=\u001b[39m Snapshots[increasing_indices]\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'dlc-models\\\\iteration-0\\\\openfieldOct30-trainset95shuffle1\\\\train'"
     ]
    }
   ],
   "source": [
    "%cd C:\\Users\\louise.xu\\projects\\Deeplabcut\\examples\\openfield-Pranav-2018-10-30\n",
    "\n",
    "deeplabcut.create_labeled_video('config.yaml', ['./videos/m3v1mp4.mp4'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DEEPLABCUT]",
   "language": "python",
   "name": "conda-env-DEEPLABCUT-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
