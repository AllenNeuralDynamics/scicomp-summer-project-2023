{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e88b1092",
   "metadata": {},
   "source": [
    "# Comparison between DLC and Sleap\n",
    "\n",
    "\n",
    "Sleap provides a couple of small videos at the [sleap repo under the test data folder](https://github.com/talmolab/sleap/tree/develop/tests/data/videos), as well as a sample video from the [sleap datasets repo](https://github.com/talmolab/sleap-datasets) that is more refined and also contains some labels. DeepLabCut provides example videos in their [git repo](https://github.com/DeepLabCut/DeepLabCut/tree/main/examples), and we will be using the [example mice video](https://github.com/DeepLabCut/DeepLabCut/blob/main/examples/Reaching-Mackenzie-2018-08-30/videos/reachingvideo1.avi) for this comparison. \n",
    "\n",
    "Comparison pipeline:\n",
    "\n",
    "- Generate 20 frames to label, train on 80% (16 frames) and test on 20% (4 frames)\n",
    "- Train model\n",
    "- Predict on entire video\n",
    "\n",
    "Evaluation metrics:\n",
    "\n",
    "- Pixel error on test labeled frames\n",
    "- Visualize Predictions Labeled video\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d5ced2",
   "metadata": {},
   "source": [
    "### How to follow this notebook\n",
    "\n",
    "To follow through this notebook, you must have a sleap conda environment installed as described in the README. Then change the kernel of this notebook to `Python [sleap]`. Now you will be able to run the commands in the notebook within the sleap conda environment. \n",
    "\n",
    "### Table of contents\n",
    "\n",
    "- [Sleap Model training](#SLEAP-TRAINING)\n",
    "    - [Train-Test Split Preprocessing](#Train-Test-Split-Preprocessing)\n",
    "    - [Train-Test Split in Terminal](#Train-Test-in-Terminal)\n",
    "- [(Optional) Prediction-assisted labeling in Sleap GUI](#(Optional)-Prediction-assisted-labeling-in-GUI)\n",
    "- [Sleap Model evaluation in notebook](#SLEAP-EVALUATION)\n",
    "- [Sleap Predictions post-processing](#SLEAP-PREDICTION-post-processing)\n",
    "    - [Sleap Generate Prediction video](#SLEAP-Generate-Predictions-Video)\n",
    "    \n",
    "    \n",
    "[Use DLC labels in Sleap (in progress)](#Use-DLC-labels-in-Sleap-(in-progress))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde1af31",
   "metadata": {},
   "source": [
    "# SLEAP TRAINING\n",
    "\n",
    "Use the GUI for labeling and prediction-assisted training as usual. It is easy to do prediction-assisted training and inference in the GUI, although it is certainly doable through the terminal as well. The only complication with the GUI comes  when you would like to do a train-test split, and there are several approaches to do it manually, either through the terminal, the GUI, or the jupyter notebook. \n",
    "\n",
    "Train-test split is tricky in Sleap becuase by default all labeled frames will be used for training. Suppose we generate 20 suggested frames, then we want to use 16 of them for training and 4 of them for testing. The default validation fraction is 0.1, which means that 0.1 of the training frames (i.e. 2 frames in this case) will not be used for training directly, instead will be used for tuning hyperparameters and early stopping. Model metrics would be generated based on its performance on the 4 testing frames. \n",
    "\n",
    "[Train config file documentation](https://sleap.ai/develop/api/sleap.nn.config.data.html#sleap.nn.config.data.LabelsConfig)\n",
    "\n",
    "- Training labels: used for training\n",
    "- Validation labels: not used for training, used for hyperparameters and early stopping, default sample 0.1 from training labels\n",
    "- Test labels: not used for training, used for benchmarking\n",
    "\n",
    "## Train-Test Split Preprocessing\n",
    "\n",
    "Since Sleap does not provide a native train-test split in the GUI, we need to generate separate train and test label files manually. \n",
    "\n",
    "First, create a folder inside the Home Folder to store all SLEAP related files for this project, for example `sleap-mouse-topview`. \n",
    "\n",
    "Then in the SLEAP GUI, generate 20 frames and save as `labels.20frames.slp` file, where 16 will be training frames and 4 will be testing frames. \n",
    "\n",
    "- Open a new project in the GUI using the `labels.20frames.slp` file, label 4 frames, and `Export Label Package` to a `labels.20frames4labeled.pkg.slp` file in Home Folder.\n",
    "- Open a new project in the GUI using the `labels.20frames.slp` file, label the remaining 16 frames, and `Export Label Package` to a `labels.20frames16labeled.slp` file in Home Folder.\n",
    "- In the same project, click `Predict - Run Training` in the toolbox, and mofidify train configurations: e.g. configure 10 epoch for each model, predict on Nothing, set run prefix to \"appstream_train16_test4\". \n",
    "- DO NOT click run training. Instead, click `Export Training Job` and save the zip file to the Home Folder with a descriptive name. This will be the training job folder name, for example `labels.appstream0inference20frames16labeled.slp.training_job`.\n",
    "\n",
    "Go to Appstream's home folder and unzip the training job folder. It should contain a `labels.20frames16labeled.pkg.slp` file and some training job config files. Move the `labels.20frames4labeled.pkg.slp` file into this folder as well.\n",
    "\n",
    "\n",
    "NOTE: Save labels via `Predict - Export Labels` and not `File - Save As` if you want to use them elsewhere (e.g. on local computer). If directly Save As .. in GUI after labeling, the labeled frames in the `.slp` file will reference the original video file with its appstream location, which wouldn't be available if you moved the files. However, if saved via Export Labels, the labeled frames in the `.pkg.slp` file will only reference the `.pkg.slp` file itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31804b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd models/appstream_noinference_train16_test4230721_210307.centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290530e7",
   "metadata": {},
   "source": [
    "### Train-Test in Terminal\n",
    "\n",
    "Similar file processing but in the `appstream-terminal` training job folder. Change directory to training job folder, then in terminal, run \n",
    "\n",
    "    sleap-train centroid.json labels.20frames16labeled.pkg.slp --test labels.20frames4labeled.pkg.slp\n",
    "    sleap-train centered_instance.json labels.20frames16labeled.pkg.slp --test labels.20frames4labeled.pkg.slp\n",
    "\n",
    "Models will be generated under the training job folder in `sleap-mouse-topview/appstream-terminal/models`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad92ed16",
   "metadata": {},
   "source": [
    "Run inference on the entire video using the trained models. \n",
    "\n",
    "    sleap-track C:\\s3-mount\\dlc-sample-videos\\mouse-movement-videos\\mouse-top-view.mp4 \\\n",
    "        -m models\\appstream_noinference_train16_test4_fromscript230721_210307.centroid \\\n",
    "        -m models\\appstream_noinference_train16_test4_fromscript230721_210307.centered_instance \\\n",
    "        -o sleap-mouse-topview-video.predictions.slp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d059ab26",
   "metadata": {},
   "source": [
    "### Train in GUI\n",
    "\n",
    "Similar file processing but in the `appstream-modifyjson` training job folder. Change directory to training job folder, and modify both json files so that the training label and test labels paths point to the `.pkg.slp` files saved in the folder. \n",
    "\n",
    "```\n",
    "\"training_labels\": \"D:/PhotonUser/My Files/Home Folder/sleap-mouse-topview/appstream_modifyjson/labels.20frames16labeled.pkg.slp\",\n",
    "\"validation_labels\": null,\n",
    "\"validation_fraction\": 0.1,\n",
    "\"test_labels\": \"D:/PhotonUser/My Files/Home Folder/sleap-mouse-topview/appstream_modifyjson/labels.20frames4labeled.pkg.slp\",\n",
    "```\n",
    "\n",
    "Use these json files in the GUI train configurations window. \n",
    "\n",
    "Models will be generated under the sleap folder in `sleap-mouse-topview/models`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841dcc3f",
   "metadata": {},
   "source": [
    "### Train in Notebook\n",
    "\n",
    "In the jupyter notebook, change directory to the training job folder and start training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a792a912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment following lines and run once to change notebook working directpory\n",
    "# %cd \"My Files\\Home Folder\\sleap-mouse-topview\"\n",
    "# %cd \"labels.appstream0inference20frames16labeled.slp.training_job\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f14edfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sleap-train centroid.json labels.20frames16labeled.pkg.slp --test labels.20frames4labeled.pkg.slp\n",
    "!sleap-train centered_instance.json labels.20frames16labeled.pkg.slp --test labels.20frames4labeled.pkg.slp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dde937",
   "metadata": {},
   "source": [
    "Trained model results will be generated under a `models` folder in the training job folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd79514c",
   "metadata": {},
   "source": [
    "## (Optional) Prediction-assisted labeling in GUI\n",
    "\n",
    "Open `predictions.slp` file in GUI, correct predicted frames that are incorrect. Save labels to `predictions-relabel.slp` file in training job folder.  \n",
    "\n",
    "Then, you could run the training entirely in the GUI (method 1), or extract a .slp file with the user-labeled corrections and choose to re-train in the GUI (method 2) or re-train in the terminal as shown above (method 3). You could choose to merge the user-labeled corrections to the original project file with `Files-Merge Data From ...`, in order to train with both the originally labeled frames and the corrected frames. Instructions here reference the [official documentation](https://sleap.ai/develop/guides/merging.html). \n",
    "\n",
    "Method 1: In GUI, click `Predict-Run Training`, models will be generated under training job folder in `sleap-mouse-topview/appstream-terminal/models`. \n",
    "\n",
    "Method 2: In Sleap GUI toolbar, click `Delete All Predictions...` to delete all predicted instances and be left with user-labeled corrections only. Save the corrected labels to another `.slp` file so that you can merge into another project in the GUI. \n",
    "\n",
    "Method 3: You may also use the following python code to generate the `only_relabels.slp` file with only user-labeled corrections, then run training in the terminal as demonstrated above. Note that the file name cannot contain hyphens (`-`). \n",
    "\n",
    "    labels = sleap.load_file('preditions-relabel.slp')\n",
    "    only_relabels = labels.with_user_labels_only()\n",
    "    only_relabels.save(\"only_relabels.slp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a07dc7a",
   "metadata": {},
   "source": [
    "## SLEAP EVALUATION\n",
    "\n",
    "You can analyze the performance of the trained models using the metrics available in the model files. You can follow the steps below in a jupyter notebook or in a similar python environment. If you would like to export resulting model files for analysis somewhere else, run `tar -acf out.zip /path/to/models`, and download the out.zip file to local computer. \n",
    "\n",
    "Here is an example view of what the models folder should contain. If you want to analyze the centroid model, go to `models\\appstream_noinference_train16_test4230721_210307.centroid`. The test pixel error is available in the `metrics.test.npz` file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "a5a667e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows\n",
      " Volume Serial Number is 2E94-A0A3\n",
      "\n",
      " Directory of C:\\Users\\louise.xu\\Downloads\\appstream-terminal\\models\\appstream_noinference_train16_test4_fromscript230721_210307.centered_instance\n",
      "\n",
      "07/25/2023  11:33 AM    <DIR>          .\n",
      "07/25/2023  11:33 AM    <DIR>          ..\n",
      "07/25/2023  11:33 AM        69,145,416 best_model.h5\n",
      "07/25/2023  11:33 AM             5,975 initial_config.json\n",
      "07/25/2023  11:33 AM            18,040 labels_gt.test.slp\n",
      "07/25/2023  11:33 AM            20,088 labels_gt.train.slp\n",
      "07/25/2023  11:33 AM            18,040 labels_gt.val.slp\n",
      "07/25/2023  11:33 AM            15,944 labels_pr.test.slp\n",
      "07/25/2023  11:33 AM            16,448 labels_pr.train.slp\n",
      "07/25/2023  11:33 AM            15,944 labels_pr.val.slp\n",
      "07/25/2023  11:33 AM             2,147 metrics.test.npz\n",
      "07/25/2023  11:33 AM             2,471 metrics.train.npz\n",
      "07/25/2023  11:33 AM             1,991 metrics.val.npz\n",
      "07/25/2023  11:33 AM             8,200 training_config.json\n",
      "07/25/2023  11:33 AM             1,472 training_log.csv\n",
      "              13 File(s)     69,272,176 bytes\n",
      "               2 Dir(s)  55,850,446,848 bytes free\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DIR = Path(\"C:/Users/louise.xu/Downloads/appstream-terminal\")\n",
    "MODELS_DIR = DIR / \"models\"\n",
    "CENTROID_MODEL = MODELS_DIR / \"appstream_noinference_train16_test4_fromscript230721_210307.centered_instance\"\n",
    "\n",
    "!dir $CENTROID_MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75267498",
   "metadata": {},
   "source": [
    "Here is how you can load the model metrics for different splits, i.e. train, validation, and test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "5fda9e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====train====\n",
      "mAP: 0.8126787678767876\n",
      "pixel error: 1.2829211239840028\n",
      "====validation====\n",
      "mAP: 0.02524752475247525\n",
      "pixel error: 3.9137164844054566\n",
      "====test====\n",
      "mAP: 0.06386138613861386\n",
      "pixel error: 32.214755664959654\n"
     ]
    }
   ],
   "source": [
    "import sleap\n",
    "\n",
    "#help(sleap.load_metrics)\n",
    "metrics_val = sleap.load_metrics(CENTROID_MODEL, split=\"val\")\n",
    "metrics_train = sleap.load_metrics(CENTROID_MODEL, split=\"train\")\n",
    "metrics_test = sleap.load_metrics(CENTROID_MODEL, split=\"test\")\n",
    "\n",
    "print(\"====train====\")\n",
    "print(\"mAP:\", metrics_train[\"oks_voc.mAP\"])\n",
    "print(\"pixel error:\", metrics_train[\"dist.avg\"])\n",
    "print(\"====validation====\")\n",
    "print(\"mAP:\", metrics_val[\"oks_voc.mAP\"])\n",
    "print(\"pixel error:\", metrics_val[\"dist.avg\"])\n",
    "print(\"====test====\")\n",
    "print(\"mAP:\", metrics_test[\"oks_voc.mAP\"])\n",
    "print(\"pixel error:\", metrics_test[\"dist.avg\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ed27bf",
   "metadata": {},
   "source": [
    "## SLEAP PREDICTION post-processing\n",
    "\n",
    "You can also directly process the predictions made on the entire video using the predictions.slp file. Here is a quick view of what data it contains, but we will convert it into a .h5 file for easier analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "1137d9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictedInstance(video=Video(filename=C:\\Users\\louise.xu\\Downloads\\mouse-top-view.mp4, shape=(2330, 480, 640, 1), backend=MediaVideo), frame_idx=0, points=[head: (77.0, 88.6, 1.02), tailBase: (140.4, 187.7, 0.95)], score=0.94, track=None, tracking_score=0.00)\n",
      "[[ 76.97714233  88.58641815   1.02416515]\n",
      " [140.41918945 187.72146606   0.94858468]]\n",
      "(PredictedPoint(x=76.97714233398438, y=88.58641815185547, visible=True, complete=False, score=1.024165153503418), PredictedPoint(x=140.419189453125, y=187.72146606445312, visible=True, complete=False, score=0.9485846757888794))\n"
     ]
    }
   ],
   "source": [
    "DOWNLOADS = Path(\"C:/Users/louise.xu/Downloads\")\n",
    "#labels = sleap.load_file(str(TRAIN_JOB / \"sleap-mouse-topview-video.predictions-labeled.pkg.slp\"))\n",
    "predictions = Labels.load_file(str(DOWNLOADS / \"sleap-mouse-topview-video.predictions.slp\"), video_search = str(TRAIN_JOB / \"mouse-top-view.mp4\"))\n",
    "print(predictions.predicted_instances[0])\n",
    "print(predictions.predicted_instances[0].points_and_scores_array)\n",
    "print(predictions.predicted_instances[0].points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d3991b",
   "metadata": {},
   "source": [
    "Run the following codeblock or run the command in terminal to convert convert .slp files into .h5 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "0a449281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exporting to SLEAP Analysis file...\n",
      "\ttrack_names: 0\n",
      "\tnode_names: 2\n",
      "\tedge_names: 1\n",
      "\tedge_inds: 1\n",
      "\ttracks: (2330, 2, 2, 1)\n",
      "\ttrack_occupancy: (1, 2330)\n",
      "\tpoint_scores: (2330, 2, 1)\n",
      "\tinstance_scores: (2330, 1)\n",
      "\ttracking_scores: (2330, 1)\n",
      "\tlabels_path: C:/Users/louise.xu/Downloads/sleap-mouse-topview-video.predictions.slp\n",
      "\tvideo_path: C:/Users/louise.xu/Downloads\\mouse-top-view.mp4\n",
      "\tvideo_ind: 0\n",
      "\tprovenance: {\"model_paths\": [\"models\\\\appstream_noinference_train16_test4_fromscript230721_210307.centroid\\\\training_config.json\", \"models\\\\appstream_noinference_train16_test4_fromscript230721_210307.centered_instance\\\\training_config.json\"], \"predictor\": \"TopDownPredictor\", \"sleap_version\": \"1.3.0\", \"platform\": \"Windows-10-10.0.17763-SP0\", \"command\": \"C:\\\\miniconda3\\\\envs\\\\sleap\\\\Scripts\\\\sleap-track C:\\\\s3-mount\\\\dlc-sample-videos\\\\mouse-movement-videos\\\\mouse-top-view.mp4 -m models\\\\appstream_noinference_train16_test4_fromscript230721_210307.centroid -m models\\\\appstream_noinference_train16_test4_fromscript230721_210307.centered_instance -o sleap-mouse-topview-video.predictions.slp\", \"data_path\": \"C:\\\\s3-mount\\\\dlc-sample-videos\\\\mouse-movement-videos\\\\mouse-top-view.mp4\", \"output_path\": \"sleap-mouse-topview-video.predictions.slp\", \"total_elapsed\": 62.926466941833496, \"start_timestamp\": \"2023-07-24 18:30:39.201081\", \"finish_timestamp\": \"2023-07-24 18:31:42.127548\", \"args\": {\"data_path\": \"C:\\\\s3-mount\\\\dlc-sample-videos\\\\mouse-movement-videos\\\\mouse-top-view.mp4\", \"models\": [\"models\\\\appstream_noinference_train16_test4_fromscript230721_210307.centroid\", \"models\\\\appstream_noinference_train16_test4_fromscript230721_210307.centered_instance\"], \"frames\": \"\", \"only_labeled_frames\": false, \"only_suggested_frames\": false, \"output\": \"sleap-mouse-topview-video.predictions.slp\", \"no_empty_frames\": false, \"verbosity\": \"rich\", \"video.dataset\": null, \"video.input_format\": \"channels_last\", \"video.index\": \"\", \"cpu\": false, \"first_gpu\": false, \"last_gpu\": false, \"gpu\": \"auto\", \"max_edge_length_ratio\": 0.25, \"dist_penalty_weight\": 1.0, \"batch_size\": 4, \"open_in_gui\": false, \"peak_threshold\": 0.2, \"tracking.tracker\": null, \"tracking.target_instance_count\": null, \"tracking.pre_cull_to_target\": null, \"tracking.pre_cull_iou_threshold\": null, \"tracking.post_connect_single_breaks\": null, \"tracking.clean_instance_count\": null, \"tracking.clean_iou_threshold\": null, \"tracking.similarity\": null, \"tracking.match\": null, \"tracking.robust\": null, \"tracking.track_window\": null, \"tracking.min_new_track_points\": null, \"tracking.min_match_points\": null, \"tracking.img_scale\": null, \"tracking.of_window_size\": null, \"tracking.of_max_levels\": null, \"tracking.save_shifted_instances\": null, \"tracking.kf_node_indices\": null, \"tracking.kf_init_frame_count\": null}}\n",
      "Saved as mouse-labels.h5\n"
     ]
    }
   ],
   "source": [
    "!sleap-convert \"C:/Users/louise.xu/Downloads/sleap-mouse-topview-video.predictions.slp\" --format analysis --output mouse-labels.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "1b2f88ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\louise.xu\\Downloads\n",
      "===filename===\n",
      "mouse-labels.h5\n",
      "\n",
      "===HDF5 datasets===\n",
      "['edge_inds', 'edge_names', 'instance_scores', 'labels_path', 'node_names', 'point_scores', 'provenance', 'track_names', 'track_occupancy', 'tracking_scores', 'tracks', 'video_ind', 'video_path']\n",
      "\n",
      "===locations (tracks) data shape===\n",
      "(2330, 2, 2, 1)\n",
      "\n",
      "===nodes===\n",
      "0: head\n",
      "1: tailBase\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\Users\\louise.xu\\Downloads\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "filename = \"mouse-labels.h5\" # or your own exported filename\n",
    "\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    dset_names = list(f.keys())\n",
    "    locations = f[\"tracks\"][:].T\n",
    "    node_names = [n.decode() for n in f[\"node_names\"][:]]\n",
    "\n",
    "print(\"===filename===\")\n",
    "print(filename)\n",
    "print()\n",
    "\n",
    "print(\"===HDF5 datasets===\")\n",
    "print(dset_names)\n",
    "print()\n",
    "\n",
    "print(\"===locations (tracks) data shape===\")\n",
    "print(locations.shape)\n",
    "print()\n",
    "\n",
    "print(\"===nodes===\")\n",
    "for i, name in enumerate(node_names):\n",
    "    print(f\"{i}: {name}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2348c86b",
   "metadata": {},
   "source": [
    "You can also make a `.csv` file containing the predicted locations from the `.h5` file. This is useful if you would like to import this into DeepLabCut. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "34dbb9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "locations_csv = locations.reshape((2330, 4))\n",
    "header= \"\"\n",
    "for name in node_names:\n",
    "    header += name + \"-x, \" + name + \"-y, \"\n",
    "np.savetxt(\"C:/Users/louise.xu/Downloads/sleap-mouse-predictions.csv\", locations_csv, delimiter=\",\", header=header, comments=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd54cd12",
   "metadata": {},
   "source": [
    "### SLEAP Generate Predictions Video\n",
    "\n",
    "Once you have the `predictions.slp` file containing predictions of the entire video, you can generate a video file visualizing these prediction instances. \n",
    "\n",
    "Method 1 (GUI): Open the `predictions.slp` file. In the GUI toolbar, click `View-Render Video Clip with Instances...`. \n",
    "\n",
    "Method 2 (Terminal): Change to the directory containing the `predictions.slp` file. Then enter the following command. I set the fps to be 30, the same as The sample video fps value. Notice that the output name must contain a valid extension such as `.avi`\n",
    "\n",
    "    sleap-render predictions.slp --fps 30 --output predictions-video.avi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61776e5",
   "metadata": {},
   "source": [
    "# Use DLC labels in Sleap (in progress)\n",
    "\n",
    "You can `File-Import-DeepLabCut dataset` to import a DeepLabCut `.csv` file containing the user label coordinates. This will open a Sleap GUI window containing only the labeled video frames. Save this as a `labels.fromdlc.slp` file. \n",
    "\n",
    "Next open a new Sleap project and load the raw video file. Then click `File-Merge into Project` to merge the `labels.fromdlc.slp` file into the current project. \n",
    "\n",
    "- Run into error during merge : \"Labels.skeleton can only be used when there is only a single skeleton saved in the labels. Use Labels.skeletons instead.\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sleap]",
   "language": "python",
   "name": "conda-env-sleap-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
